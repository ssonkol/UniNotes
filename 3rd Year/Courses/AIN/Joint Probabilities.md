# Joint Probabilities
Tag: #review 

---
## Definitions
Probability Theory 
> A branch of mathematics concerned with the analysis of random phenomena.

Random Variable
>A numerical outcome of a random phenomenon

Naïve Bayes
>It is a classification technique based on Bayes’ Theorem with an assumption of independence among predictors. In simple terms, a Naïve Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.


## Notes
#### Joint Probabilities

A joint Probability distribution for a set of random variables (r.v.s) gives the probability of every atomic event on those r.v.s (i.e. every sample point)

Example:
![[Pasted image 20220921122033.png]] [2]

**Every** question about a domain can be answered by the joint distribution because every event is a sum of sample points.

###### Inference by enumeration
Given 
![[Pasted image 20220921122345.png]] [2]

then for a toothache
![[Pasted image 20220921122419.png]] [2]

or for a toothache or cavity
![[Pasted image 20220921122451.png]] [2]

We can also compute conditional probabilities:
![[Pasted image 20220921122726.png]] [2]

## Questions
##### Question 1
![[Pasted image 20220921122554.png]] [2]
###### Answer

---
## Footnote

Backlinks : [[Probability Theory]]

Sources:
1. 
	- Name: lect02 - 1 Uncertainty.pdf
	- Author: Frederik Mallmann-Trenn
2. 
	- Name: lect02 - 2 Probability Basics.pdf
	- Author: Frederik Mallmann-Trenn
3. 
	- Name: lect02 - 3 Independence and Conditional Independence.pdf
	- Author: Frederik Mallmann-Trenn
4. 
	- Name: lect02 - 4 Bayes Rule.pdf
	- Author: Frederik Mallmann-Trenn