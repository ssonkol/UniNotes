# Gaussian Mixture Models
---
## Notes

A mixture model is a combination of probability models.

In general we might mix K base distributions so that ![[Pasted image 20230130172353.png]]

Where $\pi _k$ are the mixing weights.

In other words, the probability of an element xi is the sum of the probabilities assigned to x i by each of the probability models in the mixture.

### Gaussian Mixture Model

When Gaussians are univariate we have: ![[Pasted image 20230130172555.png]]
where ![[Pasted image 20230130173100.png]] is the variance

**Univariate** refers to the case where the data being modelled consists of a single variable or feature, which can be represented by a scalar value. 

For example, let's consider a dataset of heights of individuals, where each data point represents the height of a single person. If we are interested in modelling this dataset using a GMM, and we only consider the height variable without incorporating any other features such as weight, age, etc., then we would be using a univariate GMM.


- The probabilistic model for representing a number of normally distributed sub-populations within an overall population.
	- Modelling human height might be hard to fit under a single gaussian model

### Estimating the means of K Gaussians

1. Assume that D is generated by a mixture model
2. First, pick the distribution with equal probability 1/k
3. Then pick a value according to the distribution
4. Repeat



---
Backlink: [[Probabilistic Models]]

