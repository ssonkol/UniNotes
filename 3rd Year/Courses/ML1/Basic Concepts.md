# Basic Concepts
---

## Notes

### Overfitting
When we learn very flexible models, it is possible that the result is too specialised to the data - this is what we call **overfitting**.

This results in low errors on the training data but high errors on new examples.

---
Backlink: [[Introduction to Machine Learning]]